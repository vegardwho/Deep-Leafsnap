{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aedb2693-c5d0-421a-b822-84f321028304",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import scipy.spatial as spatial\n",
    "import matplotlib.pyplot as plt\n",
    "import random \n",
    "import pandas as pd\n",
    "import os\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from sklearn.datasets import fetch_species_distributions\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import copy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "\n",
    "from pyproj import Proj, transform\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import re\n",
    "\n",
    "import utils\n",
    "from utils import long_running \n",
    "\n",
    "#copied from Kevin Barnes/kbarnes3: https://gist.github.com/kbarnes3/3fb7d353e9bdd3efccd5\n",
    "\n",
    "import ctypes\n",
    "import platform\n",
    "\n",
    "ES_CONTINUOUS = 0x80000000\n",
    "ES_SYSTEM_REQUIRED = 0x00000001\n",
    "\n",
    "\n",
    "def _set_thread_execution(state):\n",
    "    ctypes.windll.kernel32.SetThreadExecutionState(state)\n",
    "\n",
    "\n",
    "def prevent_standby():\n",
    "    if platform.system() == 'Windows':\n",
    "        _set_thread_execution(ES_CONTINUOUS | ES_SYSTEM_REQUIRED)\n",
    "\n",
    "\n",
    "def allow_standby():\n",
    "    if platform.system() == 'Windows':\n",
    "        _set_thread_execution(ES_CONTINUOUS)\n",
    "\n",
    "\n",
    "def long_running(func):\n",
    "    def inner(*args, **kwargs):\n",
    "        prevent_standby()\n",
    "        result = func(*args, **kwargs)\n",
    "        allow_standby()\n",
    "        return result\n",
    "    return inner\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "acdc756b-1c5c-42e2-b0c6-9178deaa306a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "model_name = \"vgg19_pretrained\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "343f1a41-0d34-46d4-b1b2-8d004a83491f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vjosv\\AppData\\Local\\Temp\\ipykernel_10192\\1423672116.py:9: DtypeWarning: Columns (14,15,24,25,26,37,38,39,40,46) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dat = pd.read_csv('C:/Users/vjosv/master/dataset/top185_in_oslo_area.csv')\n",
      "C:\\Users\\vjosv\\AppData\\Local\\Temp\\ipykernel_10192\\1423672116.py:4: FutureWarning: This function is deprecated. See: https://pyproj4.github.io/pyproj/stable/gotchas.html#upgrading-to-pyproj-2-from-pyproj-1\n",
      "  lon, lat = transform(utm_proj, lonlat_proj, df['Østkoordinat'].values, df['Nordkoordinat'].values)\n"
     ]
    }
   ],
   "source": [
    "def convert_utm_to_latlon(df, zone_number, zone_letter):\n",
    "    utm_proj = Proj(proj='utm', zone=zone_number, ellps='WGS84', south=(zone_letter < 'N'))\n",
    "    lonlat_proj = Proj(proj='latlong', datum='WGS84')\n",
    "    lon, lat = transform(utm_proj, lonlat_proj, df['Østkoordinat'].values, df['Nordkoordinat'].values)\n",
    "    \n",
    "    return pd.DataFrame({'Longitude': lon, 'Latitude': lat})\n",
    "\n",
    "\n",
    "dat = pd.read_csv('C:/Users/vjosv/master/dataset/top185_in_oslo_area.csv')\n",
    "dat = dat[['Id','Østkoordinat','Nordkoordinat','Vitenskapelig navn']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dat['points']= [[i,j] for i, j in zip(dat.Østkoordinat, dat.Nordkoordinat)]\n",
    "\n",
    "df_latlon = convert_utm_to_latlon(dat, 33, 'N') \n",
    "\n",
    "\n",
    "dat['lat']=df_latlon['Latitude']\n",
    "dat['long']=df_latlon['Longitude']\n",
    "\n",
    "\n",
    "\n",
    "#oslo area:\n",
    "#lowerleft, upperleft, upper right, lower right,\n",
    "\n",
    "\n",
    "lat_long_oslo = [(58.998141, 9.574585), (60.351413, 9.574585), (60.351413, 12.540894),(58.998141,12.540894)]\n",
    "\n",
    "# dat['Østkoordinat']>lat_long_oslo[0][0]\n",
    "\n",
    "\n",
    "dat = dat.loc[(dat['lat']>lat_long_oslo[0][0])  & (dat['lat']<lat_long_oslo[1][0]) & (dat['long']>lat_long_oslo[0][1 ]) & (dat['long']<lat_long_oslo[2][1])]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "points = dat[['Østkoordinat','Nordkoordinat']].to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "point_tree = spatial.cKDTree(points)\n",
    "\n",
    "\n",
    "science_names = dat['Vitenskapelig navn'].unique()\n",
    "indexes = [i for i in range(len(dat['Vitenskapelig navn'].unique()))]\n",
    "\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "random.shuffle(indexes)\n",
    "\n",
    "\n",
    "names_mapping = {science_name : index for (science_name,index) in zip(science_names,indexes)}\n",
    "index_mapping = {index : science_name for (science_name,index) in zip(science_names,indexes)}\n",
    "\n",
    "def distance_between_points(point, list_of_points):\n",
    "    return [np.sqrt(np.power(point[0]-lop[0],2)+np.power(point[1]-lop[1],2)) for lop in list_of_points]\n",
    "\n",
    "\n",
    "\n",
    "def get_points_within(df_row, distance=1000):\n",
    "    id = int(df_row['Id'].iloc[0])\n",
    "    return_list = point_tree.query_ball_point([[int(df_row['Østkoordinat'].iloc[0]),int(df_row['Nordkoordinat'].iloc[0])]], distance)[0]\n",
    "    return_dat = dat.iloc[return_list]\n",
    "    return_list = list(return_dat['Id'])\n",
    "    return_list.remove(id)\n",
    "    return return_list\n",
    "    \n",
    "def sample_plant_position(plant,df):\n",
    "    if type(plant) == str:\n",
    "        return dat[dat['Vitenskapelig navn'] == plant].sample(1)\n",
    "    elif type(plant) == int:\n",
    "        return dat[dat['Vitenskapelig navn'] == index_mapping[plant]].sample(1)\n",
    "\n",
    "def kernel_density_estimate_value(point_row,dat,bandwidth = 0.5):\n",
    "    # print(point_row)\n",
    "    # print(dat)\n",
    "    if point_row.index[0] in list(dat.index):\n",
    "        np_dat_lat_long = dat.drop(point_row.index[0])[['lat','long']].to_numpy()\n",
    "    else:\n",
    "        np_dat_lat_long = dat[['lat','long']].to_numpy()\n",
    "    kde = KernelDensity(bandwidth=bandwidth)\n",
    "    # print(np_dat_lat_long)\n",
    "    if len(np_dat_lat_long)==0:\n",
    "        return 0\n",
    "    kde.fit(np_dat_lat_long)\n",
    "    np_point = np.array([[point_row['lat'].iloc[0],point_row['long'].iloc[0]]])\n",
    "    return np.exp(kde.score_samples(np_point))[0]\n",
    "\n",
    "def get_points_within_square(point, dat,side_length = 3000):\n",
    "    return_dat = dat[dat['Østkoordinat']>point['Østkoordinat'].iloc[0]-side_length]\n",
    "    return_dat = return_dat[return_dat['Østkoordinat']<point['Østkoordinat'].iloc[0]+ side_length]\n",
    "    return_dat = return_dat[return_dat['Nordkoordinat']>point['Nordkoordinat'].iloc[0]- side_length]\n",
    "    return_dat = return_dat[return_dat['Nordkoordinat']<point['Nordkoordinat'].iloc[0]+ side_length]\n",
    "    return return_dat\n",
    "\n",
    "# within_square =get_points_within_square(v,dat)\n",
    "\n",
    "# within_square\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_points_within(df_row, distance=1000):\n",
    "    id = int(df_row['Id'].iloc[0])\n",
    "    return_list = point_tree.query_ball_point([[int(df_row['Østkoordinat'].iloc[0]),int(df_row['Nordkoordinat'].iloc[0])]], distance)[0]\n",
    "    return_dat = dat.iloc[return_list]\n",
    "    return_list = list(return_dat['Id'])\n",
    "    return_list.remove(id)\n",
    "    return return_list\n",
    "    \n",
    "def sample_plant_position(plant,df):\n",
    "    if type(plant) == str:\n",
    "        return dat[dat['Vitenskapelig navn'] == plant].sample(1)\n",
    "    elif type(plant) == int:\n",
    "        return dat[dat['Vitenskapelig navn'] == index_mapping[plant]].sample(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_knn_classifier(samples_pos_list,dat,n=1000):\n",
    "    sample_pos_indexes = [sp.index[0] for sp in samples_pos_list if sp.index[0] in list(dat.index)]\n",
    "    \n",
    "    dat_removed_samples = dat.drop(index=sample_pos_indexes)\n",
    "    category = []\n",
    "    for k in dat_removed_samples['Vitenskapelig navn']:\n",
    "        category.append(names_mapping[k])\n",
    "        \n",
    "    category = np.array(category)\n",
    "    points_np= np.array(list(dat_removed_samples['points']))\n",
    "    oversample = imblearn.over_sampling.KMeansSMOTE()\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    X, y = oversample.fit_resample(points_np, category) \n",
    "    warnings.filterwarnings(\"default\")\n",
    "    \n",
    "    neigh = KNeighborsClassifier(n_neighbors=n)\n",
    "    neigh.fit(X, y)\n",
    "    return neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a29cea36-259d-4dd3-a4cd-0682c18660a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def augment_output(output, augment):\n",
    "    output_aug = torch.nn.functional.softmax(output, dim=1)\n",
    "    output_aug = output_aug * augment\n",
    "    output_aug = output_aug * 1/torch.sum(output_aug) \n",
    "    return torch.log(output_aug)\n",
    "\n",
    "def augment_output2(output, augment, zero_tensor_kde001):\n",
    "    output_aug = torch.nn.functional.softmax(output, dim=1)\n",
    "    augment = augment + zero_tensor_kde001*augment.min()\n",
    "    output_aug = output_aug + augment\n",
    "    output_aug = output_aug * 1/torch.sum(output_aug) \n",
    "    \n",
    "    return torch.log(output_aug)\n",
    "\n",
    "def kde_augmentet_output(sample_pos_list,output, dat, bandwidth):\n",
    "    \n",
    "    weight_tensor_kde = np.zeros((output.size(0),185))\n",
    "    zero_tensor_kde = np.ones((output.size(0),185))\n",
    "    for j, sample_pos in enumerate(sample_pos_list):\n",
    "        within_square =get_points_within_square(sample_pos,dat)\n",
    "        for plant_name in within_square.value_counts('Vitenskapelig navn').index:\n",
    "            within_square_ = within_square[within_square['Vitenskapelig navn']==plant_name]\n",
    "        \n",
    "            pj = names_mapping[plant_name]\n",
    "            pj_value = kernel_density_estimate_value(sample_pos,within_square_,bandwidth = bandwidth)\n",
    "            weight_tensor_kde[j][pj] = pj_value\n",
    "            zero_tensor_kde[j][pj] = 0\n",
    "    weight_tensor_kde = torch.tensor(weight_tensor_kde)\n",
    "    zero_tensor_kde = torch.tensor(zero_tensor_kde)\n",
    "    \n",
    "    output_aug_kde = augment_output2(output,weight_tensor_kde,zero_tensor_kde)\n",
    "\n",
    "    return output_aug_kde\n",
    "    \n",
    "stats_distance1 = norm(\n",
    "    loc=0, \n",
    "    scale=250\n",
    ")\n",
    "\n",
    "stats_distance2 = norm(\n",
    "    loc=0, \n",
    "    scale=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "86ecb96c-470e-430a-91e2-07c6db59a3a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "names_mapping = []\n",
    "index_mapping = []\n",
    "for i in range(20):\n",
    "    random.shuffle(indexes)\n",
    "\n",
    "    names_mapping.append({science_name : index for (science_name,index) in zip(science_names,indexes)})\n",
    "    index_mapping.append({index : science_name for (science_name,index) in zip(science_names,indexes)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "689289d9-fa3c-42a2-a60b-7e285f46114f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_files = [ i for i in os.listdir(f'saved_output/{model_name}_validating_output/') if 'output' in i]\n",
    "output_files\n",
    "max_b=0\n",
    "max_e = 0\n",
    "for output_file in output_files:\n",
    "    of = re.findall('\\d+$',output_file)\n",
    "    if int(of[0]) > max_b:\n",
    "        max_b = int(of[0])\n",
    "    a= output_file.split('_')\n",
    "    if int(a[1][1:]) >= max_e:\n",
    "        max_e = int(a[1][1:])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61135ab9-ce64-4451-8d22-7f15a084f4c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/93 [00:00<?, ?it/s]\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|████▏                                                                              | 1/20 [00:19<06:19, 19.97s/it]\u001b[A\n",
      " 10%|████████▎                                                                          | 2/20 [00:40<06:00, 20.01s/it]\u001b[A\n",
      " 15%|████████████▍                                                                      | 3/20 [01:01<05:52, 20.75s/it]\u001b[A\n",
      " 20%|████████████████▌                                                                  | 4/20 [01:21<05:25, 20.34s/it]\u001b[A\n",
      " 25%|████████████████████▊                                                              | 5/20 [01:42<05:07, 20.52s/it]\u001b[A\n",
      " 30%|████████████████████████▉                                                          | 6/20 [02:02<04:48, 20.58s/it]\u001b[A\n",
      " 35%|█████████████████████████████                                                      | 7/20 [02:22<04:25, 20.41s/it]\u001b[A\n",
      " 40%|█████████████████████████████████▏                                                 | 8/20 [02:43<04:05, 20.43s/it]\u001b[A\n",
      " 45%|█████████████████████████████████████▎                                             | 9/20 [03:03<03:43, 20.36s/it]\u001b[A\n",
      " 50%|█████████████████████████████████████████                                         | 10/20 [03:24<03:24, 20.44s/it]\u001b[A\n",
      " 55%|█████████████████████████████████████████████                                     | 11/20 [03:44<03:03, 20.36s/it]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [04:04<02:41, 20.18s/it]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████████▎                            | 13/20 [04:24<02:22, 20.29s/it]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████████▍                        | 14/20 [04:44<02:00, 20.16s/it]\u001b[A\n",
      " 75%|█████████████████████████████████████████████████████████████▌                    | 15/20 [05:05<01:41, 20.26s/it]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 16/20 [05:25<01:21, 20.27s/it]\u001b[A\n",
      " 85%|█████████████████████████████████████████████████████████████████████▋            | 17/20 [05:46<01:01, 20.56s/it]\u001b[A\n",
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 18/20 [06:06<00:40, 20.29s/it]\u001b[A\n",
      " 95%|█████████████████████████████████████████████████████████████████████████████▉    | 19/20 [06:27<00:20, 20.46s/it]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [06:46<00:00, 20.34s/it]\u001b[A\n",
      "  1%|▊                                                                              | 1/93 [06:46<10:23:53, 406.88s/it]\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|████▏                                                                              | 1/20 [00:19<06:18, 19.91s/it]\u001b[A\n",
      " 10%|████████▎                                                                          | 2/20 [00:40<06:08, 20.45s/it]\u001b[A\n",
      " 15%|████████████▍                                                                      | 3/20 [01:00<05:41, 20.09s/it]\u001b[A\n",
      " 20%|████████████████▌                                                                  | 4/20 [01:21<05:26, 20.39s/it]\u001b[A\n",
      " 25%|████████████████████▊                                                              | 5/20 [01:40<04:58, 19.91s/it]\u001b[A\n",
      " 30%|████████████████████████▉                                                          | 6/20 [01:59<04:33, 19.52s/it]\u001b[A\n",
      " 35%|█████████████████████████████                                                      | 7/20 [02:18<04:11, 19.34s/it]\u001b[A\n",
      " 40%|█████████████████████████████████▏                                                 | 8/20 [02:36<03:50, 19.22s/it]\u001b[A\n",
      " 45%|█████████████████████████████████████▎                                             | 9/20 [02:55<03:29, 19.02s/it]\u001b[A\n",
      " 50%|█████████████████████████████████████████                                         | 10/20 [03:14<03:09, 18.99s/it]\u001b[A\n",
      " 55%|█████████████████████████████████████████████                                     | 11/20 [03:33<02:49, 18.86s/it]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [03:51<02:30, 18.85s/it]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████████▎                            | 13/20 [04:10<02:12, 18.88s/it]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████████▍                        | 14/20 [04:29<01:52, 18.83s/it]\u001b[A\n",
      " 75%|█████████████████████████████████████████████████████████████▌                    | 15/20 [04:48<01:34, 18.87s/it]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 16/20 [05:07<01:15, 18.90s/it]\u001b[A\n",
      " 85%|█████████████████████████████████████████████████████████████████████▋            | 17/20 [05:26<00:56, 18.87s/it]\u001b[A\n",
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 18/20 [05:45<00:37, 18.91s/it]\u001b[A\n",
      " 95%|█████████████████████████████████████████████████████████████████████████████▉    | 19/20 [06:04<00:18, 18.90s/it]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [06:23<00:00, 19.17s/it]\u001b[A\n",
      "  2%|█▋                                                                              | 2/93 [13:10<9:56:05, 393.03s/it]\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|████▏                                                                              | 1/20 [00:18<05:59, 18.95s/it]\u001b[A\n",
      " 10%|████████▎                                                                          | 2/20 [00:37<05:38, 18.82s/it]\u001b[A\n",
      " 15%|████████████▍                                                                      | 3/20 [00:56<05:20, 18.86s/it]\u001b[A\n",
      " 20%|████████████████▌                                                                  | 4/20 [01:15<05:00, 18.76s/it]\u001b[A\n",
      " 25%|████████████████████▊                                                              | 5/20 [01:33<04:41, 18.78s/it]\u001b[A\n",
      " 30%|████████████████████████▉                                                          | 6/20 [01:52<04:22, 18.75s/it]\u001b[A\n",
      " 35%|█████████████████████████████                                                      | 7/20 [02:11<04:04, 18.80s/it]\u001b[A\n",
      " 40%|█████████████████████████████████▏                                                 | 8/20 [02:30<03:45, 18.80s/it]\u001b[A\n",
      " 45%|█████████████████████████████████████▎                                             | 9/20 [02:49<03:27, 18.82s/it]\u001b[A\n",
      " 50%|█████████████████████████████████████████                                         | 10/20 [03:07<03:07, 18.79s/it]\u001b[A\n",
      " 55%|█████████████████████████████████████████████                                     | 11/20 [03:26<02:49, 18.79s/it]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [03:45<02:30, 18.77s/it]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████████▎                            | 13/20 [04:04<02:12, 18.89s/it]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████████▍                        | 14/20 [04:24<01:54, 19.11s/it]\u001b[A\n",
      " 75%|█████████████████████████████████████████████████████████████▌                    | 15/20 [04:43<01:35, 19.06s/it]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 16/20 [05:02<01:16, 19.01s/it]\u001b[A\n",
      " 85%|█████████████████████████████████████████████████████████████████████▋            | 17/20 [05:21<00:56, 18.97s/it]\u001b[A\n",
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 18/20 [05:39<00:37, 18.97s/it]\u001b[A\n",
      " 95%|█████████████████████████████████████████████████████████████████████████████▉    | 19/20 [05:59<00:19, 19.02s/it]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [06:18<00:00, 18.90s/it]\u001b[A\n",
      "  3%|██▌                                                                             | 3/93 [19:28<9:39:18, 386.21s/it]\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|████▏                                                                              | 1/20 [00:19<06:02, 19.10s/it]\u001b[A\n",
      " 10%|████████▎                                                                          | 2/20 [00:38<05:44, 19.14s/it]\u001b[A\n",
      " 15%|████████████▍                                                                      | 3/20 [00:57<05:25, 19.13s/it]\u001b[A\n",
      " 20%|████████████████▌                                                                  | 4/20 [01:16<05:04, 19.03s/it]\u001b[A\n",
      " 25%|████████████████████▊                                                              | 5/20 [01:35<04:44, 18.99s/it]\u001b[A\n",
      " 30%|████████████████████████▉                                                          | 6/20 [01:54<04:25, 18.99s/it]\u001b[A\n",
      " 35%|█████████████████████████████                                                      | 7/20 [02:13<04:07, 19.04s/it]\u001b[A\n",
      " 40%|█████████████████████████████████▏                                                 | 8/20 [02:32<03:47, 18.96s/it]\u001b[A\n",
      " 45%|█████████████████████████████████████▎                                             | 9/20 [02:52<03:32, 19.36s/it]\u001b[A\n",
      " 50%|█████████████████████████████████████████                                         | 10/20 [03:11<03:12, 19.28s/it]\u001b[A\n",
      " 55%|█████████████████████████████████████████████                                     | 11/20 [03:30<02:53, 19.23s/it]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [03:49<02:32, 19.11s/it]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████████▎                            | 13/20 [04:08<02:13, 19.09s/it]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████████▍                        | 14/20 [04:27<01:54, 19.09s/it]\u001b[A\n",
      " 75%|█████████████████████████████████████████████████████████████▌                    | 15/20 [04:46<01:34, 18.97s/it]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 16/20 [05:05<01:15, 18.97s/it]\u001b[A\n",
      " 85%|█████████████████████████████████████████████████████████████████████▋            | 17/20 [05:24<00:56, 18.95s/it]\u001b[A\n",
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 18/20 [05:43<00:37, 18.98s/it]\u001b[A\n",
      " 95%|█████████████████████████████████████████████████████████████████████████████▉    | 19/20 [06:02<00:19, 19.03s/it]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [06:21<00:00, 19.06s/it]\u001b[A\n",
      "  4%|███▍                                                                            | 4/93 [25:49<9:29:58, 384.25s/it]\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|████▏                                                                              | 1/20 [00:18<05:59, 18.90s/it]\u001b[A\n",
      " 10%|████████▎                                                                          | 2/20 [00:37<05:40, 18.92s/it]\u001b[A\n",
      " 15%|████████████▍                                                                      | 3/20 [00:56<05:19, 18.77s/it]\u001b[A\n",
      " 20%|████████████████▌                                                                  | 4/20 [01:15<05:01, 18.85s/it]\u001b[A\n",
      " 25%|████████████████████▊                                                              | 5/20 [01:34<04:44, 18.94s/it]\u001b[A\n",
      " 30%|████████████████████████▉                                                          | 6/20 [01:53<04:23, 18.84s/it]\u001b[A\n",
      " 35%|█████████████████████████████                                                      | 7/20 [02:12<04:07, 19.03s/it]\u001b[A\n",
      " 40%|█████████████████████████████████▏                                                 | 8/20 [02:31<03:48, 19.04s/it]\u001b[A\n",
      " 45%|█████████████████████████████████████▎                                             | 9/20 [02:50<03:30, 19.14s/it]\u001b[A\n",
      " 50%|█████████████████████████████████████████                                         | 10/20 [03:09<03:10, 19.08s/it]\u001b[A\n",
      " 55%|█████████████████████████████████████████████                                     | 11/20 [03:28<02:51, 19.04s/it]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [03:48<02:33, 19.16s/it]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████████▎                            | 13/20 [04:07<02:13, 19.04s/it]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████████▍                        | 14/20 [04:26<01:54, 19.04s/it]\u001b[A\n",
      " 75%|█████████████████████████████████████████████████████████████▌                    | 15/20 [04:44<01:34, 18.99s/it]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 16/20 [05:04<01:16, 19.05s/it]\u001b[A\n",
      " 85%|█████████████████████████████████████████████████████████████████████▋            | 17/20 [05:23<00:57, 19.02s/it]\u001b[A\n",
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 18/20 [05:41<00:37, 18.94s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "\n",
    "def sample_plant_position(plant,df,index):\n",
    " \n",
    "    if type(plant) == str:\n",
    "        return dat[dat['Vitenskapelig navn'] == plant].sample(1)\n",
    "    elif type(plant) == int:\n",
    "        return dat[dat['Vitenskapelig navn'] == index_mapping[index][plant]].sample(1)\n",
    "\n",
    "\n",
    "\n",
    "random.seed(10)\n",
    "names_mapping = []\n",
    "index_mapping = []\n",
    "for i in range(20):\n",
    "    random.shuffle(indexes)\n",
    "    names_mapping.append({science_name : index for (science_name,index) in zip(science_names,indexes)})\n",
    "    index_mapping.append({index : science_name for (science_name,index) in zip(science_names,indexes)})\n",
    "\n",
    "    \n",
    "# @long_running\n",
    "def create_samples_and_points_around(start_batch):\n",
    "    for e in range(1):#max_e+1):\n",
    "        for b in tqdm(range(max_b+1)):\n",
    "            output = torch.load(f'saved_output/{model_name}_validating_output/output_e{e}_b{b}')\n",
    "            target = torch.load(f'saved_output/{model_name}_validating_output/target_b{b}')\n",
    "            sample_pos_list=[]\n",
    "            weight_tensors = [] \n",
    "\n",
    "            for i in tqdm(range(20)):\n",
    "\n",
    "                for meter in [500,600,700,800,900,1000,1100,1200,1300,1400,1500]:\n",
    "                    weight_tensor = np.ones((output.size(0),185))*0.1\n",
    "                    sample_pos_list = []\n",
    "                    for j in range(output.size(0)):\n",
    "\n",
    "                        sample_pos = sample_plant_position(int(target[j]),dat,i)\n",
    "                        \n",
    "                        sample_pos_list.append(sample_pos)\n",
    "                        \n",
    "                    if b >=start_batch:\n",
    "                        for sample_pos in sample_pos_list:\n",
    "                            points_in_area_list = get_points_within(sample_pos,meter)\n",
    "                            points_in_area = dat[dat['Id'].isin(points_in_area_list)]\n",
    "\n",
    "                            indexes_in_area = [ names_mapping[i][ii] for ii in list(points_in_area['Vitenskapelig navn'].unique())]\n",
    "\n",
    "                            for k in indexes_in_area:\n",
    "                                weight_tensor[j][k]=1\n",
    "\n",
    "                        \n",
    "                        weight_tensor = torch.from_numpy(weight_tensor)\n",
    "\n",
    "                        torch.save(weight_tensor,f'saved_output/{model_name}_validating_output/sampled_{meter}m_batch{b}_cofiguration{i}')\n",
    "\n",
    "                            # print(weight_tensors)\n",
    "        # kde_augmentet_output()\n",
    "        \n",
    "create_samples_and_points_around(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "933e52c3-0211-4809-adb3-2d5dc4aa6b54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 185)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_tensor_1000[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "64c2f049-23e5-4e91-a3b3-54570c0c3d68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sampled_1200m_batch0_cofiguration19'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a0212e79-605f-4748-ad4b-496ad18ac671",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = torch.load(f'saved_output/{model_name}_validating_output/sampled_{500}m_batch{b}_cofiguration{1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b3429319-6ce1-49f2-af71-9eda42e62015",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07a5030-87d9-46ea-b9d9-88c2beea501d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
